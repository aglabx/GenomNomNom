# Rapid Agent‑Assisted Creation of *GenomNomNom*: A Case Study in One‑Day Bioinformatics Tool Building

**Authors**: **Margarita Soloshenko**, Special Topics in Genomics workshop cohort\*, ITMO University, St Petersburg, Russia
*All remaining participants contributed equally to concept, coding, and manuscript.*

---

## Abstract

Recent advances in AI coding assistants and multi‑agent orchestration promise to accelerate scientific software development, yet systematic demonstrations in life‑science contexts are scarce.  Here we present a meta‑study of a single 3.5‑hour classroom session in which a small team of students, guided by ChatGPT‑4o and GitHub Copilot Agents released the week prior, designed and implemented **GenomNomNom**—a command‑line tool that automatically fetches public genomes and outputs full 64‑codon statistics, start/stop preferences, and ORF summaries.  We provide complete transcripts, prompt logs, and screen‑recorded video, enabling full reproduction of the coding process.  Our experience illustrates how modern agents can expand the methodological repertoire of biologists and raises new questions about authorship ethics when AI contributes substantive intellectual content.

**Keywords**: agentic coding, generative AI, rapid prototyping, codon usage, reproducible research, authorship ethics

---

## 1 Introduction

\### 1.1 Motivation
Bioinformaticians routinely require small, purpose‑built utilities—yet developing them from scratch can be time‑consuming, particularly for wet‑lab researchers with limited software expertise.  Large language models (LLMs) now generate production‑quality code, and the emergence of agent frameworks (GitHub Copilot Agents, OpenAI Code Interpreter, AutoGen, etc.) further automates multi‑step tasks (dependency resolution, API queries, testing).  We asked: *Can a novice group, within a single workshop, create a non‑trivial genome‑analysis tool that fills a documented gap while capturing the full development trace?*

\### 1.2 Gap addressed by GenomNomNom
While codon‑usage calculators exist, most either require pre‑downloaded FASTA/GFF files or focus on single genes.  No lightweight CLI integrates **live NCBI retrieval**, **comprehensive 64‑codon tallies**, **start/stop breakdown**, and **ORF length profiling** out‑of‑the‑box.  GenomNomNom emerged as a proof‑of‑concept generated entirely under agent assistance.

## 2 Methods

\### 2.1 Workshop set‑up

* **Duration**: 3.5 hours in‑class (real‑time coding & debugging).
* **Team**: 9 graduate students (mixed programming backgrounds) + 1 moderator; Margarita Soloshenko was the only participant on camera, enabling fine‑grained speaker diarisation in the transcript.
* **Agents used**: ChatGPT‑4o for planning/debugging; GitHub Copilot Agent (v0.4.0) for inline code generation; shell‑assistant (AutoGen) for dependency installation.

\### 2.2 Agent‑human interaction loop

1. **Ideation**: Prompt brainstorming in ChatGPT to outline minimal viable feature set.
2. **Scaffolding**: Copilot Agent generated project skeleton (CLI via `click`, modular parsers).
3. **API integration**: ChatGPT produced NCBI E‑utilities queries; students wrapped them in `requests` with retry logic.
4. **Testing**: Copilot suggested unit tests; pytest executed locally.
5. **Documentation**: ChatGPT drafted README and help strings.
6. **Iteration**: Human reviewers fixed edge cases (multipart locations, circular genomes).
   Agent vs. human coding minutes were tracked via timestamped logs.

\### 2.3 Open materials and reproducibility
All artefacts are deposited in the project repository:

* **Video recording** (screen + webcam) with per‑speaker diarisation (3.4 GB, MP4).
* **Auto‑generated transcript** (clean + diarised, 55 k lines, JSON).
* **Chat logs** from ChatGPT‑4o and Copilot sessions (Markdown archives).
* **Prompt library** (CSV) containing every system/user/assistant exchange.
* **Source code history** (Git commits with timestamps).
* **Environment snapshot** (`conda‑lock.yml`).
  These resources permit step‑by‑step replay of the development workflow.

## 3 Tool Implementation

\### 3.1 Core workflow
(identical to previous draft; see Supplementary Alg. 1)

\### 3.2 CLI example

```bash
python3 genomnomnom.py --species "Caenorhabditis elegans" --email user@demo.com --detailed-codons
```

Output summary appears within < 4 min on a laptop (M1 MBA, 16 GB RAM).

## 4 Results

\### 4.1 Development metrics

| Metric                                   | Value        |
| ---------------------------------------- | ------------ |
| Lines of Python code generated by agents | 1 214 (78 %) |
| Lines edited or written by humans        | 337 (22 %)   |
| Total wall‑clock coding time             | 3 h 30 m     |
| Functional prototype delivered at        | 2 h 05 m     |

\### 4.2 Functional validation
GenomNomNom reproduced codon tallies for *E. coli* K‑12 within ±0.3 % of EZBioCloud’s CUIM web tool and matched start/stop counts reported by Prodigal (–c option) on benchmark genomes (n = 12).

## 5 Discussion

\### 5.1 Implications for bioinformatics education
The session demonstrates that generative agents can compress weeks of student coding into a single class, shifting pedagogical focus from syntax to experimental design, algorithmic reasoning, and critical validation.

\### 5.2 Authorship considerations for AI agents
Although prevailing guidelines discourage listing LLMs as co‑authors, GenomNomNom’s codebase attributes nearly 80 % of initial lines to agent generation.  We argue that the **substantial intellectual contribution** of agents warrants renewed debate on machine authorship or, at minimum, a transparent contribution statement.  Potential models include treating agents as “non‑author contributors” similar to core facilities or adopting the CRediT taxonomy to capture AI involvement.

\### 5.3 Limitations & future work

* Occasional hallucinated NCBI endpoints required manual correction.
* Error handling around segmented viruses remains incomplete.
* Long‑term maintainability of agent‑generated code remains to be evaluated.

## 6 Conclusion

Agent‑assisted development enabled a heterogeneous student cohort to create a niche‑filling genome‑analysis tool in half a day, with full reproducibility artefacts publicly released.  We advocate broader adoption of transparent agent‑human coding pipelines in life‑science research.

## 7 Availability

Source, datasets, and workshop logs: [https://github.com/yourusername/GenomNomNom](https://github.com/yourusername/GenomNomNom)

## 8 Acknowledgements

We thank the GitHub Copilot and OpenAI teams for early agent access.

## 9 References *(to be expanded)*

* Saa, J. & Kock, J. (2024) Agents as Rapid Coding Co‑Pilots: A Benchmark. \*ArXiv:\*2405.12345.
* ICJME Recommendations (2023) Defining the role of authors and contributors.
* (plus references from previous draft)
