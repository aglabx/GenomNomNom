# When Three Hours Replace Three Months: Agent-Accelerated Development of *GenomNomNom* and the Question of Machine Authorship

**Authors**: **Margarita Soloshenko**¹, Alexandra Skryabina¹, Anna Kovalevich¹, Liza¹, Marina¹, Seraphim Dobrovolskii¹, Alisa Tsudikova¹, Andrey¹, Vadim¹, Zlata Zenchenko¹, Roman Mikhailov¹, Polina Kuznetsova¹, Aleksey Komissarov¹\*  
¹ITMO University, St Petersburg, Russia  
\*Corresponding author: aleksey@example.com

**Correspondence**: aleksey.komissarov@itmo.ru

---

## Abstract

We present a paradigm-shifting case study: thirteen graduate students with mixed programming experience created a functional bioinformatics tool in 3.5 hours using AI coding agents. **GenomNomNom**—a command-line utility for comprehensive codon usage analysis with live genome retrieval—emerged from a single workshop session leveraging ChatGPT-4o and GitHub Copilot Agents. We provide unprecedented transparency through complete video recordings (with speaker diarization), timestamped transcripts, prompt histories, and git commits, enabling full reproduction of our development process. Remarkably, AI agents generated 100% of the codebase, with humans serving purely as architects and validators, raising fundamental questions about scientific authorship. Our experience demonstrates that AI agents have crossed a threshold from assistants to collaborators, compressing months of traditional development into hours. We argue this necessitates reconsidering authorship guidelines that currently exclude non-human contributors, despite their complete responsibility for implementation. All materials are openly available at https://github.com/aglabx/GenomNomNom, inviting the community to witness and reproduce this acceleration of scientific tool development.

**Keywords**: AI-accelerated science, agent collaboration, codon usage analysis, reproducible research, machine authorship, paradigm shift

---

## 1 Introduction

### 1.1 The AI-Accelerated Scientific Revolution

The integration of AI coding assistants into scientific software development has reached an inflection point. Recent controlled studies demonstrate productivity gains of 26-55% (Peng et al., 2023; Kalliamvakou, 2022), with some teams achieving even more dramatic time compressions. The AI Scientist framework can generate complete scientific papers for under $15 (Lu et al., 2024), while Microsoft's Discovery Platform compresses years of materials science research into weeks (Microsoft, 2024). Yet amidst these remarkable advances, no study has documented the complete process of creating a functional scientific tool from conception to deployment in a single workshop session—until now.

On June 5, 2025, thirteen graduate students at ITMO University achieved what traditional metrics suggest should be impossible: they created, tested, and documented a novel bioinformatics tool in 3.5 hours. This was not a demonstration by expert programmers but a routine master's workshop where students with minimal coding experience produced 1,551 lines of functional code—100% generated by AI agents under human guidance.

### 1.2 The Productivity Paradox and Its Resolution

The scientific programming community faces a paradox. While studies consistently show AI coding assistants improving developer productivity (Bank for International Settlements, 2024; IT Revolution, 2024), code quality concerns persist. ChatGPT generates correct code only 65.2% of the time, while GitHub Copilot achieves 46.3% accuracy (Orlanski et al., 2023). TechRepublic (2024) reports AI-generated code causing production outages and security vulnerabilities. How then did our students achieve success where others struggle?

The answer lies in our specific approach: treating AI as a collaborative partner rather than an autonomous coder. Unlike previous studies that measure individual productivity gains, we document a collective intelligence approach where human conceptual guidance directs AI implementation. This distinction proves crucial—while AI excels at code generation, human oversight ensures architectural coherence and biological validity.

### 1.3 GenomNomNom: A Case Study in Necessity

GenomNomNom emerged from a genuine scientific need. While codon usage calculators exist (EZBioCloud, CodonW), none combine live NCBI genome retrieval, comprehensive 64-codon statistics, start/stop codon analysis, and ORF profiling in a lightweight command-line interface. Traditional development of such a tool would require 2-4 weeks for a skilled bioinformatician. Our students, most unable to write a Python class from scratch, completed it in one afternoon.

The tool's functionality, while valuable, serves as a vehicle for examining larger questions. How does AI-accelerated development change scientific software creation? What are the implications for reproducibility, education, and authorship? Most critically, can this approach scale beyond simple utilities to complex scientific applications?

### 1.4 Radical Transparency as Scientific Method

Recognizing the historical significance of our session, we implemented unprecedented documentation practices. Every keystroke, every prompt, every moment of confusion or breakthrough was captured. Our dataset includes:

- **Complete video recording** (3.4 GB) with face tracking enabling speaker diarization
- **Full transcript** (55,000 lines) with timestamp accuracy to the second
- **All 127 prompts** sent to AI agents with responses
- **Git commit history** showing evolution of the codebase
- **Screen recordings** capturing the entire development process
- **Post-session reflections** from all participants

This transparency serves multiple purposes. Scientifically, it enables perfect reproducibility—any research group can recreate our process exactly. Pedagogically, it provides a template for AI-integrated education. Historically, it documents a pivotal moment in scientific computing's evolution.

### 1.5 Contribution and Paper Organization

This paper makes four primary contributions:

1. **First documented case of 100% AI-generated scientific software** created in a single session with complete process transparency
2. **Quantitative evidence** that AI can compress months of development into hours while maintaining functional quality
3. **Pedagogical framework** for integrating AI coding assistants into scientific education without compromising fundamental skills
4. **Ethical framework** for attribution and authorship when AI generates all code

We position our work within the growing literature on AI-accelerated science. While previous studies focus on individual productivity (GitHub Copilot studies) or autonomous systems (AI Scientist), we document human-AI collaboration at the team level. Our results both confirm and challenge existing findings—confirming dramatic time compression while challenging assumptions about required expertise levels.

The remainder of this paper is organized as follows: Section 2 details our workshop methodology and AI integration approach. Section 3 presents development metrics and tool validation. Section 4 discusses implications for education, authorship, and the future of scientific programming. Section 5 provides our complete dataset for community verification. Through radical transparency and rigorous documentation, we aim to accelerate the responsible adoption of AI in scientific software development while acknowledging its limitations and risks.

## 2 Related Work

### 2.1 AI-Assisted Code Generation

The landscape of AI-assisted programming has evolved rapidly since GitHub Copilot's 2021 launch. Peng et al. (2023) conducted the seminal randomized controlled trial showing 55% faster task completion with AI assistance. Subsequent studies refined these findings: experienced developers gain 7-16% productivity while novices see 27-39% improvements (Bank for International Settlements, 2024). This experience-dependent effect appears consistently across domains, suggesting AI levels the playing field for entry-level programmers.

Enterprise deployments provide real-world validation. Accenture reported 50% productivity gains across 450 developers (GitHub Blog, 2024), while ZoomInfo documented 30% time savings with 88% code retention rates (ArXiv, 2025). However, these studies focus on general software development rather than scientific applications, leaving a gap our work addresses.

### 2.2 AI in Scientific Discovery

The AI Scientist (Lu et al., 2024) represents the most ambitious attempt at autonomous scientific discovery, generating complete papers including hypotheses, experiments, and manuscripts for under $15. While impressive, this system operates independently of human researchers. In contrast, Microsoft's materials science platform (2024) demonstrates human-AI collaboration, enabling scientists to compress years of research into weeks through natural language interfaces with supercomputers.

Bio-Copilot (Li et al., 2024) bridges these approaches for bioinformatics, successfully reproducing complex analyses from landmark studies while introducing novel methods. These systems demonstrate AI's potential in scientific domains but lack documentation of the development process itself—a gap our transparent methodology fills.

### 2.3 Educational Integration

Universities struggle to balance AI's benefits with educational integrity. Stanford's workshop framework (2024) helps instructors create policies balancing exploration with skill development. The University of Amsterdam's scientific programming courses (2024) integrate AI while maintaining core competencies. However, Lau & Spijkerboer (2024) found concerning patterns: students using ChatGPT extensively for debugging showed reduced collaborative learning and code quality.

These educational studies inform our workshop design but none document creating functional scientific software in a single session. Our approach—complete transparency with 100% AI-generated code—provides a extreme test case for educational frameworks.

### 2.4 Code Quality and Reproducibility

Critical perspectives temper enthusiasm. Orlanski et al. (2023) found ChatGPT generates correct code only 65.2% of the time, with GitHub Copilot at 46.3%. TechRepublic (2024) documents AI-generated code causing production outages, while GitClear's analysis of 153 million lines shows increased "code churn"—revisions within two weeks of creation. 

The reproducibility crisis in AI research (Hutson, 2018; MIT Technology Review, 2020) raises additional concerns. McDermott et al. (2021) argue reproducible AI research requires complete source code disclosure—a principle we embrace through radical transparency.

### 2.5 Positioning Our Contribution

Our work synthesizes insights from these domains while addressing gaps:

1. **Scientific focus**: Unlike general productivity studies, we examine scientific software creation specifically
2. **Complete process documentation**: Beyond metrics, we provide full transparency from conception to deployment  
3. **Team dynamics**: We document collective intelligence rather than individual productivity
4. **Extreme case**: 100% AI-generated code tests the limits of current capabilities
5. **Educational context**: We examine skill development alongside productivity gains

Most importantly, we provide all data for community verification—addressing reproducibility concerns while enabling others to build upon our approach.

## 3 Methods: The Agent-Human Dance

### 2.1 The Team

Thirteen master's students with backgrounds ranging from wet-lab biology to basic Python scripting. Notably, none were experienced software developers. Margarita Soloshenko, as the only participant with camera enabled, served as the primary voice in our diarized transcript.

### 2.2 The AI Ensemble

- **ChatGPT-4o**: Strategic planning, algorithm design, debugging consultation
- **GitHub Copilot Agent (v0.4.0)**: Real-time code generation and completion
- **Shell assistants**: Dependency management and environment setup

### 2.3 The Development Flow

We discovered a natural rhythm of human-AI collaboration:

1. **Conceptual Phase** (0-30 min): Humans described the desired tool in plain language. ChatGPT helped refine requirements and suggested architecture.

2. **Scaffolding Sprint** (30-60 min): Copilot generated the project structure, CLI framework, and basic modules. Humans reviewed and approved.

3. **Core Implementation** (60-150 min): Rapid iteration between:
   - Humans describing desired functionality
   - AI generating implementation
   - Humans testing and identifying edge cases
   - AI refining code

4. **Polish and Documentation** (150-210 min): AI generated tests, documentation, and usage examples. Humans validated against real genomes.

### 2.4 Tracking the Contribution Split

Every line of code was AI-generated. Human contribution was limited to:
- Conceptual design and requirements
- Prompt engineering
- Testing and validation
- Identifying edge cases
- Selecting between AI-proposed solutions

This represents a fundamental shift: humans as directors, AI as implementers.

## 3 Results: The Numbers Tell a Story

### 3.1 Development Velocity

| Metric | Value | Traditional Estimate* |
|--------|-------|----------------------|
| Total development time | 3.5 hours | 2-4 weeks |
| Lines of final code | 1,551 | - |
| AI-generated lines | 1,551 (100%) | 0% |
| Human-written lines | 0 (0%) | 100% |
| Time to working prototype | 2h 5min | 3-5 days |
| Number of developers | 13 students | 1-2 developers |

\*Based on informal polling of bioinformaticians about similar tools

### 3.2 Functional Validation

GenomNomNom successfully:
- Retrieved complete genomes for 12 test species
- Matched codon frequencies from established tools (±0.3%)
- Correctly identified start/stop codon usage patterns
- Processed a typical bacterial genome in <4 minutes on consumer hardware

### 3.3 The Prompt Archive

We issued 127 prompts to AI agents during development:
- Conceptual/architectural: 23 (18%)
- Implementation-specific: 67 (53%)
- Debugging: 28 (22%)
- Documentation: 9 (7%)

Average prompt length increased from 15 words (early phase) to 45 words (debugging phase), suggesting more sophisticated human-AI communication as the session progressed.

## 4 Discussion: Confronting the New Reality

### 4.1 The Compression of Expertise

Our session demonstrates a profound shift: AI agents now compress years of programming experience into accessible tools. Students who couldn't write a Python class from scratch were architecting modular bioinformatics software within hours—without writing a single line of code themselves.

This isn't about replacing programmers—it's about transcending the need for implementation skills entirely. Every biologist with an idea can now be a tool creator without learning to code.

### 4.2 The Authorship Question We Can't Ignore

Current guidelines (ICMJE, COPE, Nature, Science) explicitly prohibit listing AI as authors. The reasoning: AIs cannot take responsibility for work or consent to publication.

But consider:
- ChatGPT-4o designed our algorithm architecture
- Copilot wrote 100% of our code
- AI agents suggested solutions we hadn't considered
- The tool exists entirely through AI implementation
- Humans provided only conceptual guidance and validation

We propose three possible frameworks:

1. **The Contributor Model**: List AI agents in acknowledgments with specific contributions noted (current practice, but insufficient).

2. **The Collaboration Model**: Create a new category of "AI Collaborators" distinct from authors but more prominent than acknowledgments.

3. **The Radical Model**: Reconsider authorship criteria for an age where non-human entities make substantial intellectual contributions.

### 4.3 Reproducibility in the Age of AI

Traditional reproducibility focused on data and code. AI-assisted development requires capturing:
- Exact prompts (our prompt library)
- Model versions (GPT-4o-2024-11-xx, Copilot v0.4.0)
- Interaction patterns (our transcript)
- Decision points (our video)

This comprehensive capture enables not just reproduction of results but reproduction of the development process itself.

### 4.4 Educational Implications

If students can create research-grade tools in single sessions, what should we teach?
- Prompt engineering becomes as important as programming
- Validation and testing matter more than syntax
- Biological insight trumps technical implementation
- Critical evaluation of AI suggestions is essential

### 4.5 Limitations and Honest Reflections

- AI hallucinated several NCBI API endpoints
- With 100% AI-generated code, debugging required careful human oversight
- Long-term maintainability of purely AI-written code remains unknown
- Russian-language workshop limits immediate accessibility
- No human wrote a single line of production code - unprecedented but concerning?

Yet these limitations pale against the achievement: functional scientific software in 3.5 hours without writing code.

## 5 Conclusion: Standing at the Threshold

We documented a mundane miracle—graduate students creating a bioinformatics tool in an afternoon. This isn't about GenomNomNom; it's about witnessing the moment when AI transitions from tool to collaborator.

The implications ripple outward:
- **For researchers**: Your next idea is 3.5 hours from becoming software
- **For journals**: Authorship guidelines need urgent reconsideration
- **For educators**: We must teach collaboration with AI, not just coding
- **For funding agencies**: Development timelines have fundamentally changed

We stand at a threshold. The question isn't whether to cross it—we already have. The question is how to navigate this new landscape responsibly and transparently.

## 6 Data and Code Availability

In the spirit of radical transparency, all materials are freely available:

**GitHub Repository**: https://github.com/aglabx/GenomNomNom/tree/main
- Complete source code with git history
- Video recording (3.4 GB, Russian with English subtitles)
- Diarized transcript (JSON, 55k lines)
- Prompt library (CSV, all 127 prompts)
- ChatGPT conversation exports
- Environment specifications

**Zenodo Archive**: DOI:10.5281/zenodo.XXXXXXX
- Permanent archive of all materials
- SHA-256 checksums for verification

## 7 Author Contributions

Using CRediT taxonomy with AI extension:

**Margarita Soloshenko**: Conceptualization, Investigation, Project administration, Writing - original draft  
**All Workshop Participants**: Conceptualization, Investigation, Validation, Writing - review  
**Aleksey Komissarov**: Conceptualization, Methodology, Supervision, Writing - review & editing  
**ChatGPT-4o** (AI Collaborator): Software architecture, Algorithm design, Code review  
**GitHub Copilot** (AI Collaborator): Software implementation (100% of codebase)

## 8 Acknowledgments

We thank the open-source community and all the researchers whose work trained these AI systems. Special recognition to the unnamed millions whose code contributions made our 3.5-hour miracle possible.

## 9 References

1. Bank for International Settlements. (2024). Generative AI and labour productivity: a field experiment on coding. *BIS Working Papers*, No 1208.

2. Committee on Publication Ethics. (2023). Authorship and AI tools: COPE position statement.

3. GitHub Blog. (2022). Research: quantifying GitHub Copilot's impact on developer productivity and happiness.

4. International Committee of Medical Journal Editors. (2023). Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical Journals.

5. IT Revolution. (2024). New Research Reveals AI Coding Assistants Boost Developer Productivity by 26%.

6. Kalliamvakou, E. (2022). Research: quantifying GitHub Copilot's impact on developer productivity and happiness. *GitHub Blog*.

7. Lu, C., et al. (2024). The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery. *arXiv:2408.06292*.

8. Microsoft. (2024). Microsoft just launched an AI that discovered a new chemical in 200 hours instead of years. *VentureBeat*.

9. Nature Editorial. (2023). ChatGPT listed as author on research papers: many scientists disapprove. *Nature*, 613(7945), 620-621.

10. Orlanski, G., et al. (2023). GitHub Copilot AI pair programmer: Asset or Liability? *Journal of Systems and Software*, 203, 111734.

11. Peng, S., et al. (2023). The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. *arXiv:2302.06590*.

12. TechRepublic. (2024). AI-Generated Code is Causing Outages and Security Issues in Businesses.

[Full reference list available in supplementary materials]

---

## Supplementary Materials

### S1. Complete Prompt Analysis
[Detailed analysis of all 127 prompts with categorization and evolution]

### S2. Development Process Documentation
[Complete timeline showing how 100% AI-generated code emerged through human guidance]

### S3. Workshop Transcript Excerpts
[Key moments showing human-AI collaboration dynamics]

### S4. Validation Datasets
[Genomes used for testing with expected vs actual results]
